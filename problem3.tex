\section{Problem 3}
By definition of maximum likehood and as the dataset has iid samples we have\\
\begin{equation*}
\mathcal{L} = p(x_1,\dots,x_n|\lambda) = \prod_{i=1}^n p(x_i|\lambda)
\end{equation*}
We can now easily maximize the log-likehood, 
\begin{equation*}
\log \mathcal{L}(\lambda) = \log\prod_{i=1}^n p(x_i|\lambda)=\sum_{i=1}^n \log p(x_i|\lambda)
\end{equation*}
\begin{equation*}
\log \mathcal{L}(\lambda) = \sum_{i=1}^n \log \biggl( \frac{1}{\Gamma(a)} \lambda^a x_i^{a-1} e^{-\lambda x_i} \biggr)
\end{equation*}
\begin{equation*}
\log \mathcal{L}(\lambda) = \sum_{i=1}^n \biggl( \log\frac{1}{\Gamma(a)} + a*\log\lambda + (a-1)\log{x_i} - \lambda*x_i \biggr)
\end{equation*}
For finding a maximum (or minimum) we will take the derivative with respect of $\lambda$ and will set equal to 0.
\begin{equation*}
\frac{\partial\mathcal{L}}{\partial\lambda} = \sum_{i=1}^n \frac{\partial}{\partial\lambda} \biggl( \log\frac{1}{\Gamma(a)} + a*\log\lambda + (a-1)\log{x_i} - \lambda*x_i \biggr)
\end{equation*}
\begin{equation*}
\frac{\partial\mathcal{L}}{\partial\lambda} = \sum_{i=1}^n \biggl( \frac{a}{\lambda} - x_i \biggr)
\end{equation*}
Setting this equal to 0
\begin{equation*}
\lambda = \frac{n*a}{\sum_{i=1}^n x_i}
\end{equation*}

To figure out if it is maximum or minimum we will use the second derivative of $\lambda$.
So in order to be maximum the second derivative must be negative.

\begin{equation*}
\frac{\partial^2\mathcal{L}}{\partial\lambda^2} = \sum_{i=1}^n \biggl( -\frac{a}{\lambda^2} -1 \biggr)
\end{equation*}
As $ a > 0 $ and $\lambda^2 > 0$ then $-\frac{a}{\lambda^2} < 0$. So all the previous equation is negative.
